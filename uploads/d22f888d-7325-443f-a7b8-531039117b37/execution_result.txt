
[2025-08-17 07:51:08]
‚úÖ duckdb already installed.
----------------------------------------

[2025-08-17 07:51:08]
‚úÖ pandas already installed.
----------------------------------------

[2025-08-17 07:51:09]
‚úÖ scipy already installed.
----------------------------------------

[2025-08-17 07:51:09]
‚úÖ matplotlib already installed.
----------------------------------------

[2025-08-17 07:51:09]
‚úÖ numpy already installed.
----------------------------------------

[2025-08-17 07:51:09]
üìú Executing Code:
import duckdb
import pandas as pd
from scipy import stats
import matplotlib.pyplot as plt
import io
import base64
import json
import numpy as np

# Step 1: Connect to DuckDB and load necessary extensions
con = duckdb.connect(database=":memory:", read_only=False)
con.execute("INSTALL httpfs; LOAD httpfs;")
con.execute("INSTALL parquet; LOAD parquet;")
con.execute("SET s3_region='ap-south-1';")

# Step 2: Answer Question 1 - Which high court disposed the most cases from 2019 - 2022?
query1 = """
SELECT court, COUNT(*) as case_count
FROM read_parquet('s3://indian-high-court-judgments/metadata/parquet/year=*/court=*/bench=*/metadata.parquet')
WHERE year BETWEEN 2019 AND 2022
GROUP BY court
ORDER BY case_count DESC
LIMIT 1;
"""
result1_df = con.execute(query1).fetchdf()
most_cases_court = result1_df["court"].iloc[0]

# Save intermediate finding for Question 1
with open("uploads/d22f888d-7325-443f-a7b8-531039117b37/metadata.txt", "a") as f:
    f.write(f"Most active court (2019-2022): {most_cases_court}\n")

# Step 3: Fetch and process data for Questions 2 & 3
# Note: The court code '33~10' corresponds to the partition '33_10'
query2 = """
SELECT
    decision_date,
    date_of_registration,
    year
FROM read_parquet('s3://indian-high-court-judgments/metadata/parquet/year=*/court=33_10/bench=*/metadata.parquet')
WHERE date_of_registration IS NOT NULL AND decision_date IS NOT NULL;
"""
df = con.execute(query2).fetchdf()

# Data cleaning and feature engineering
df["decision_date"] = pd.to_datetime(df["decision_date"], errors="coerce")
df["date_of_registration"] = pd.to_datetime(
    df["date_of_registration"], format="%d-%m-%Y", errors="coerce"
)
df.dropna(subset=["date_of_registration", "decision_date"], inplace=True)
df["delay_days"] = (df["decision_date"] - df["date_of_registration"]).dt.days

# Filter out illogical data where decision date is before registration date
df = df[df["delay_days"] >= 0]

# Use a sample of up to 50,000 points for efficient regression and plotting
df_sample = df.sample(n=min(len(df), 50000), random_state=42)

# Answer Question 2: Calculate the regression slope
slope, intercept, _, _, _ = stats.linregress(df_sample["year"], df_sample["delay_days"])

# Save intermediate finding for Question 2
with open("uploads/d22f888d-7325-443f-a7b8-531039117b37/metadata.txt", "a") as f:
    f.write(f"Regression slope for court 33_10: {slope}\n")

# Answer Question 3: Generate the plot
plt.style.use("seaborn-v0_8-whitegrid")
fig, ax = plt.subplots(figsize=(8, 5))
ax.scatter(
    df_sample["year"],
    df_sample["delay_days"],
    alpha=0.3,
    edgecolors="none",
    s=20,
    label="Case Delay",
)

# Create regression line values
x_vals = np.array(sorted(df_sample["year"].unique()))
y_vals = intercept + slope * x_vals
ax.plot(x_vals, y_vals, "--", color="red", linewidth=2, label="Regression Line")

ax.set_title("Delay from Registration to Decision (Court 33_10)", fontsize=14)
ax.set_xlabel("Year", fontsize=12)
ax.set_ylabel("Delay (days)", fontsize=12)
ax.legend()
plt.tight_layout()

# Save plot to an in-memory buffer and encode as base64
buf = io.BytesIO()
plt.savefig(buf, format="webp", quality=80, dpi=75)
buf.seek(0)
image_base64 = base64.b64encode(buf.read()).decode("utf-8")
data_uri = f"data:image/webp;base64,{image_base64}"

# Save intermediate finding for Question 3
with open("uploads/d22f888d-7325-443f-a7b8-531039117b37/metadata.txt", "a") as f:
    f.write(f"Plot generated with data URI length: {len(data_uri)}\n")

# Step 4: Assemble and save the final JSON result
final_answer = {
    "Which high court disposed the most cases from 2019 - 2022?": most_cases_court,
    "What's the regression slope of the date_of_registration - decision_date by year in the court=33_10?": slope,
    "Plot the year and # of days of delay from the above question as a scatterplot with a regression line. Encode as a base64 data URI under 100,000 characters": data_uri,
}

output_path = "uploads/d22f888d-7325-443f-a7b8-531039117b37/result.json"
with open(output_path, "w") as f:
    json.dump(final_answer, f, indent=2)

print(f"Analysis complete. Final answer saved to {output_path}")

----------------------------------------

[2025-08-17 07:52:25]
‚ùå Execution error:
Traceback (most recent call last):
  File "/home/raushan/TDS_project2/uploads/d22f888d-7325-443f-a7b8-531039117b37/job_/script.py", line 81, in <module>
    plt.savefig(buf, format='webp', quality=80, dpi=75)
  File "/home/raushan/TDS_project2/venv/lib/python3.12/site-packages/matplotlib/pyplot.py", line 1251, in savefig
    res = fig.savefig(*args, **kwargs)  # type: ignore[func-returns-value]
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/raushan/TDS_project2/venv/lib/python3.12/site-packages/matplotlib/figure.py", line 3490, in savefig
    self.canvas.print_figure(fname, **kwargs)
  File "/home/raushan/TDS_project2/venv/lib/python3.12/site-packages/matplotlib/backend_bases.py", line 2186, in print_figure
    result = print_method(
             ^^^^^^^^^^^^^
  File "/home/raushan/TDS_project2/venv/lib/python3.12/site-packages/matplotlib/backend_bases.py", line 2042, in <lambda>
    print_method = functools.wraps(meth)(lambda *args, **kwargs: meth(
                                                                 ^^^^^
TypeError: FigureCanvasAgg.print_webp() got an unexpected keyword argument 'quality'

----------------------------------------

[2025-08-17 07:53:03]
‚úÖ duckdb already installed.
----------------------------------------

[2025-08-17 07:53:03]
‚úÖ pandas already installed.
----------------------------------------

[2025-08-17 07:53:03]
‚úÖ scipy already installed.
----------------------------------------

[2025-08-17 07:53:03]
‚úÖ matplotlib already installed.
----------------------------------------

[2025-08-17 07:53:03]
‚úÖ numpy already installed.
----------------------------------------

[2025-08-17 07:53:03]
üìú Executing Code:
import duckdb
import pandas as pd
from scipy import stats
import matplotlib.pyplot as plt
import io
import base64
import json
import numpy as np

# Step 1: Connect to DuckDB and load necessary extensions
con = duckdb.connect(database=":memory:", read_only=False)
con.execute("INSTALL httpfs; LOAD httpfs;")
con.execute("INSTALL parquet; LOAD parquet;")
con.execute("SET s3_region='ap-south-1';")

# Step 2: Answer Question 1 - Which high court disposed the most cases from 2019 - 2022?
query1 = """
SELECT court, COUNT(*) as case_count
FROM read_parquet('s3://indian-high-court-judgments/metadata/parquet/year=*/court=*/bench=*/metadata.parquet')
WHERE year BETWEEN 2019 AND 2022
GROUP BY court
ORDER BY case_count DESC
LIMIT 1;
"""
result1_df = con.execute(query1).fetchdf()
most_cases_court = result1_df["court"].iloc[0]

# Save intermediate finding for Question 1
with open("uploads/d22f888d-7325-443f-a7b8-531039117b37/metadata.txt", "a") as f:
    f.write(f"Most active court (2019-2022): {most_cases_court}\n")

# Step 3: Fetch and process data for Questions 2 & 3
query2 = """
SELECT
    decision_date,
    date_of_registration,
    year
FROM read_parquet('s3://indian-high-court-judgments/metadata/parquet/year=*/court=33_10/bench=*/metadata.parquet')
WHERE date_of_registration IS NOT NULL AND decision_date IS NOT NULL;
"""
df = con.execute(query2).fetchdf()

# Data cleaning and feature engineering
df["decision_date"] = pd.to_datetime(df["decision_date"], errors="coerce")
df["date_of_registration"] = pd.to_datetime(
    df["date_of_registration"], format="%d-%m-%Y", errors="coerce"
)
df.dropna(subset=["date_of_registration", "decision_date"], inplace=True)
df["delay_days"] = (df["decision_date"] - df["date_of_registration"]).dt.days

# Filter out illogical data
df = df[df["delay_days"] >= 0]

# Use a sample for efficiency
df_sample = df.sample(n=min(len(df), 50000), random_state=42)

# Answer Question 2: Calculate the regression slope
slope, intercept, _, _, _ = stats.linregress(df_sample["year"], df_sample["delay_days"])

# Save intermediate finding for Question 2
with open("uploads/d22f888d-7325-443f-a7b8-531039117b37/metadata.txt", "a") as f:
    f.write(f"Regression slope for court 33_10: {slope}\n")

# Answer Question 3: Generate the plot
plt.style.use("seaborn-v0_8-whitegrid")
fig, ax = plt.subplots(figsize=(8, 5))
ax.scatter(
    df_sample["year"],
    df_sample["delay_days"],
    alpha=0.3,
    edgecolors="none",
    s=20,
    label="Case Delay",
)

# Create regression line values
x_vals = np.array(sorted(df_sample["year"].unique()))
y_vals = intercept + slope * x_vals
ax.plot(x_vals, y_vals, "--", color="red", linewidth=2, label="Regression Line")

ax.set_title("Delay from Registration to Decision (Court 33_10)", fontsize=14)
ax.set_xlabel("Year", fontsize=12)
ax.set_ylabel("Delay (days)", fontsize=12)
ax.legend()
plt.tight_layout()

# Save plot to an in-memory buffer and encode as base64
buf = io.BytesIO()
# Corrected line: Removed the 'quality' keyword argument which caused the error.
plt.savefig(buf, format="webp", dpi=75)
buf.seek(0)
image_base64 = base64.b64encode(buf.read()).decode("utf-8")
data_uri = f"data:image/webp;base64,{image_base64}"

# Save intermediate finding for Question 3
with open("uploads/d22f888d-7325-443f-a7b8-531039117b37/metadata.txt", "a") as f:
    f.write(f"Plot generated with data URI length: {len(data_uri)}\n")

# Step 4: Assemble and save the final JSON result
final_answer = {
    "Which high court disposed the most cases from 2019 - 2022?": most_cases_court,
    "What's the regression slope of the date_of_registration - decision_date by year in the court=33_10?": slope,
    "Plot the year and # of days of delay from the above question as a scatterplot with a regression line. Encode as a base64 data URI under 100,000 characters": data_uri,
}

output_path = "uploads/d22f888d-7325-443f-a7b8-531039117b37/result.json"
with open(output_path, "w") as f:
    json.dump(final_answer, f, indent=2)

print(f"Analysis complete. Final answer saved to {output_path}")

----------------------------------------

[2025-08-17 07:54:13]
‚úÖ Code executed successfully:
Analysis complete. Final answer saved to uploads/d22f888d-7325-443f-a7b8-531039117b37/result.json

----------------------------------------

[2025-08-17 07:54:39]
üìú Executing Code:

----------------------------------------

[2025-08-17 07:54:39]
‚úÖ Code executed successfully:

----------------------------------------
